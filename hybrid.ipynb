{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsbM3hUrb2v7UAF2hFQXpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kcreation25/hybrid/blob/main/hybrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "AGCob_XxIOg1",
        "outputId": "5f0b12b3-cef2-4338-b57b-556fe2f5822b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3e78275-80ed-4888-929c-f0a97ef79bc1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3e78275-80ed-4888-929c-f0a97ef79bc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BitcoinHeistData.csv.zip to BitcoinHeistData.csv.zip\n",
            "Saving no label.csv to no label.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 🔐 HYBRID RANSOMWARE DETECTION MODEL\n",
        "# Combines Supervised (with SMOTE) + Unsupervised (Isolation Forest)\n",
        "# Weighted Ensemble: 65% Supervised + 35% Unsupervised\n",
        "# ==============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.ensemble import IsolationForest, HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ LOAD DATASETS\n",
        "# -----------------------------\n",
        "df_supervised = pd.read_csv(\"BitcoinHeistData.csv.zip\")   # Labeled dataset\n",
        "df_unsupervised = pd.read_csv(\"no label.csv\")              # Unlabeled dataset\n",
        "\n",
        "# -----------------------------\n",
        "# 2️⃣ SUPERVISED MODEL (with SMOTE and Scaling)\n",
        "# -----------------------------\n",
        "print(\"\\n🏁 Training Supervised Model with SMOTE and Scaling...\")\n",
        "\n",
        "# Prepare features and target for supervised model\n",
        "# Classify 'white' as 0 (non-malicious) and all other labels as 1 (malicious)\n",
        "X = df_supervised.drop(\"label\", axis=1)\n",
        "y = df_supervised[\"label\"].apply(lambda x: 0 if x == \"white\" else 1)\n",
        "\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in X.select_dtypes(include='object').columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Before SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Create a pipeline with SMOTE and RobustScaler\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('scaler', RobustScaler()),\n",
        "    ('hgb', HistGradientBoostingClassifier(max_iter=100, learning_rate=0.1, max_depth=5, random_state=42))\n",
        "])\n",
        "\n",
        "start_time = time.time()\n",
        "pipeline.fit(X_train, y_train)\n",
        "supervised_time = time.time() - start_time\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_prob = pipeline.predict_proba(X_test)[:, 1]  # probability of ransomware\n",
        "\n",
        "\n",
        "supervised_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n✅ Supervised Model Accuracy (with SMOTE and Scaling): {supervised_acc:.4f}\")\n",
        "print(\"⏱️ Training Time (Supervised):\", round(supervised_time, 3), \"seconds\")\n",
        "print(\"\\n📊 Classification Report (Supervised):\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Non-malicious\", \"Malicious\"]))\n",
        "\n",
        "# -----------------------------\n",
        "# 3️⃣ UNSUPERVISED MODEL (Isolation Forest)\n",
        "# -----------------------------\n",
        "print(\"\\n🏁 Training Unsupervised Model (Isolation Forest)...\")\n",
        "\n",
        "# Drop non-numeric columns\n",
        "X_unsup = df_unsupervised.drop(columns=[\"address\"], errors=\"ignore\")\n",
        "\n",
        "# Scale unsupervised data\n",
        "scaler_unsup = RobustScaler()\n",
        "X_unsup_scaled = scaler_unsup.fit_transform(X_unsup)\n",
        "\n",
        "\n",
        "unsup_model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    contamination=0.01,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "unsup_model.fit(X_unsup_scaled)\n",
        "unsup_time = time.time() - start_time\n",
        "\n",
        "unsup_scores = -unsup_model.decision_function(X_unsup_scaled)  # higher = more suspicious\n",
        "unsup_flags = unsup_model.predict(X_unsup_scaled)  # -1 = anomaly\n",
        "\n",
        "print(\"⏱️ Training Time (Unsupervised):\", round(unsup_time, 3), \"seconds\")\n",
        "print(f\"Total anomalies detected (unsupervised): {(unsup_flags == -1).sum()}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4️⃣ HYBRID ENSEMBLE COMBINATION\n",
        "# -----------------------------\n",
        "print(\"\\n🔗 Combining Supervised + Unsupervised Models...\")\n",
        "\n",
        "# Normalize both score sets to 0–1\n",
        "supervised_scaled = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())\n",
        "\n",
        "# Scale X_test before generating unsupervised scores for hybrid\n",
        "X_test_scaled = scaler_unsup.transform(X_test.drop(columns=[\"address\"], errors=\"ignore\"))\n",
        "unsup_scores_test = -unsup_model.decision_function(X_test_scaled)\n",
        "unsup_scaled = (unsup_scores_test - unsup_scores_test.min()) / (unsup_scores_test.max() - unsup_scores_test.min())\n",
        "\n",
        "\n",
        "hybrid_score = 0.65 * supervised_scaled + 0.35 * unsup_scaled\n",
        "hybrid_pred = (hybrid_score > 0.5).astype(int)\n",
        "\n",
        "# -----------------------------\n",
        "# 5️⃣ HYBRID PERFORMANCE EVALUATION\n",
        "# -----------------------------\n",
        "print(\"\\n📊 Hybrid Model Evaluation\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, hybrid_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, hybrid_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, hybrid_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# 6️⃣ TIME TO DETECTION COMPARISON\n",
        "# -----------------------------\n",
        "print(\"\\n⏱️ Detection Time Comparison:\")\n",
        "print(f\"Supervised Model: {supervised_time:.3f} sec\")\n",
        "print(f\"Unsupervised Model: {unsup_time:.3f} sec\")\n",
        "print(f\"Hybrid Model (approx): {supervised_time + unsup_time:.3f} sec\")\n",
        "\n",
        "# -----------------------------\n",
        "# 7️⃣ TEST ON UNKNOWN DATA\n",
        "# -----------------------------\n",
        "print(\"\\n🧩 Testing Hybrid Model on Unknown (Unlabeled) Dataset...\")\n",
        "\n",
        "# Scale the unknown data using the same scaler as the unsupervised model\n",
        "X_unknown_scaled = scaler_unsup.transform(df_unsupervised.drop(columns=[\"address\"], errors=\"ignore\"))\n",
        "unsup_scores_unknown = -unsup_model.decision_function(X_unknown_scaled)\n",
        "unsup_scaled_unknown = (unsup_scores_unknown - unsup_scores_unknown.min()) / (unsup_scores_unknown.max() - unsup_scores_unknown.min())\n",
        "\n",
        "\n",
        "# Combine supervised average probability with unsupervised anomaly scores\n",
        "hybrid_unsup_score = 0.65 * np.mean(y_prob) + 0.35 * unsup_scaled_unknown\n",
        "threshold = np.median(hybrid_unsup_score)\n",
        "unknown_flags = (hybrid_unsup_score > threshold).astype(int)\n",
        "\n",
        "\n",
        "print(f\"🔍 Unknown pattern detection (unlabeled dataset): Detected {unknown_flags.sum()} suspicious entries.\")\n",
        "\n",
        "print(\"\\n✅ Hybrid Model Execution Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cuEhOHHQJx2",
        "outputId": "e157c24b-f5d8-4307-c3e2-584b36a466f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🏁 Training Supervised Model with SMOTE and Scaling...\n",
            "Before SMOTE:\n",
            "label\n",
            "0    2300227\n",
            "1      33130\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✅ Supervised Model Accuracy (with SMOTE and Scaling): 0.9092\n",
            "⏱️ Training Time (Supervised): 68.583 seconds\n",
            "\n",
            "📊 Classification Report (Supervised):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-malicious       0.99      0.91      0.95    575057\n",
            "    Malicious       0.09      0.60      0.16      8283\n",
            "\n",
            "     accuracy                           0.91    583340\n",
            "    macro avg       0.54      0.76      0.56    583340\n",
            " weighted avg       0.98      0.91      0.94    583340\n",
            "\n",
            "\n",
            "🏁 Training Unsupervised Model (Isolation Forest)...\n",
            "⏱️ Training Time (Unsupervised): 5.828 seconds\n",
            "Total anomalies detected (unsupervised): 10486\n",
            "\n",
            "🔗 Combining Supervised + Unsupervised Models...\n",
            "\n",
            "📊 Hybrid Model Evaluation\n",
            "Accuracy: 0.9440086399012583\n",
            "\n",
            "Confusion Matrix:\n",
            " [[547070  27987]\n",
            " [  4675   3608]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97    575057\n",
            "           1       0.11      0.44      0.18      8283\n",
            "\n",
            "    accuracy                           0.94    583340\n",
            "   macro avg       0.55      0.69      0.58    583340\n",
            "weighted avg       0.98      0.94      0.96    583340\n",
            "\n",
            "\n",
            "⏱️ Detection Time Comparison:\n",
            "Supervised Model: 68.583 sec\n",
            "Unsupervised Model: 5.828 sec\n",
            "Hybrid Model (approx): 74.411 sec\n",
            "\n",
            "🧩 Testing Hybrid Model on Unknown (Unlabeled) Dataset...\n",
            "🔍 Unknown pattern detection (unlabeled dataset): Detected 524287 suspicious entries.\n",
            "\n",
            "✅ Hybrid Model Execution Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23aad4c8",
        "outputId": "92619bdd-6dc3-4fe5-baf0-f048dfa233b5"
      },
      "source": [
        "print(\"Original df_supervised label counts:\")\n",
        "print(df_supervised['label'].value_counts())\n",
        "\n",
        "print(\"\\nFiltered df_supervised_filtered label counts:\")\n",
        "print(df_supervised_filtered['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original df_supervised label counts:\n",
            "label\n",
            "white                          2875284\n",
            "paduaCryptoWall                  12390\n",
            "montrealCryptoLocker              9315\n",
            "princetonCerber                   9223\n",
            "princetonLocky                    6625\n",
            "montrealCryptXXX                  2419\n",
            "montrealNoobCrypt                  483\n",
            "montrealDMALockerv3                354\n",
            "montrealDMALocker                  251\n",
            "montrealSamSam                      62\n",
            "montrealCryptoTorLocker2015         55\n",
            "montrealGlobeImposter               55\n",
            "montrealGlobev3                     34\n",
            "montrealGlobe                       32\n",
            "montrealWannaCry                    28\n",
            "montrealRazy                        13\n",
            "montrealAPT                         11\n",
            "paduaKeRanger                       10\n",
            "montrealFlyper                       9\n",
            "montrealXTPLocker                    8\n",
            "montrealVenusLocker                  7\n",
            "montrealCryptConsole                 7\n",
            "montrealXLockerv5.0                  7\n",
            "montrealEDA2                         6\n",
            "montrealJigSaw                       4\n",
            "paduaJigsaw                          2\n",
            "montrealXLocker                      1\n",
            "montrealComradeCircle                1\n",
            "montrealSam                          1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Filtered df_supervised_filtered label counts:\n",
            "label\n",
            "paduaCryptoWall                12390\n",
            "montrealCryptoLocker            9315\n",
            "princetonCerber                 9223\n",
            "princetonLocky                  6625\n",
            "montrealCryptXXX                2419\n",
            "montrealNoobCrypt                483\n",
            "montrealDMALockerv3              354\n",
            "montrealDMALocker                251\n",
            "montrealSamSam                    62\n",
            "montrealCryptoTorLocker2015       55\n",
            "montrealGlobeImposter             55\n",
            "montrealGlobev3                   34\n",
            "montrealGlobe                     32\n",
            "montrealWannaCry                  28\n",
            "montrealRazy                      13\n",
            "montrealAPT                       11\n",
            "paduaKeRanger                     10\n",
            "montrealFlyper                     9\n",
            "montrealXTPLocker                  8\n",
            "montrealVenusLocker                7\n",
            "montrealCryptConsole               7\n",
            "montrealXLockerv5.0                7\n",
            "montrealEDA2                       6\n",
            "montrealJigSaw                     4\n",
            "paduaJigsaw                        2\n",
            "montrealXLocker                    1\n",
            "montrealSam                        1\n",
            "montrealComradeCircle              1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbac0841",
        "outputId": "a74aa954-f91d-481d-f702-07f9290846f1"
      },
      "source": [
        "print(X_test.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "address      0\n",
            "year         0\n",
            "day          0\n",
            "length       0\n",
            "weight       0\n",
            "count        0\n",
            "looped       0\n",
            "neighbors    0\n",
            "income       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 🔒 HYBRID RANSOMWARE DETECTION PROGRAM\n",
        "# Combines Supervised + Unsupervised Detection\n",
        "# Accepts any CSV dataset automatically\n",
        "# ==========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.ensemble import IsolationForest, HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import os\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1️⃣ LOAD ANY CSV DATASET\n",
        "# ------------------------------------------\n",
        "file_path = input(\"📂 Enter path to your dataset (CSV or ZIP file): \").strip()\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"❌ File not found. Please check the path and try again.\")\n",
        "    exit()\n",
        "\n",
        "print(\"✅ File found. Loading dataset...\")\n",
        "df = pd.read_csv(file_path, keep_default_na=True)\n",
        "print(f\"📊 Dataset loaded successfully with {len(df)} rows and {len(df.columns)} columns.\\n\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2️⃣ CHECK IF LABELED OR UNLABELED\n",
        "# ------------------------------------------\n",
        "is_labeled = 'label' in df.columns\n",
        "print(f\"🧾 Dataset Type: {'Labeled (Supervised + Unsupervised)' if is_labeled else 'Unlabeled (Unsupervised only)'}\\n\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3️⃣ UNSUPERVISED MODEL (Isolation Forest)\n",
        "# ------------------------------------------\n",
        "print(\"🤖 Running Unsupervised Detection (Isolation Forest)...\")\n",
        "unsup_df = df.select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "unsup_model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    contamination=0.01,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "unsup_model.fit(unsup_df)\n",
        "unsup_time = time.time() - start_time\n",
        "\n",
        "unsup_scores = -unsup_model.decision_function(unsup_df)\n",
        "unsup_flags = unsup_model.predict(unsup_df)\n",
        "unsup_flags = np.where(unsup_flags == -1, 1, 0)  # 1 = anomaly (ransomware)\n",
        "\n",
        "print(f\"✅ Unsupervised Detection Completed in {unsup_time:.2f} sec\")\n",
        "print(f\"🚨 Total anomalies detected (unsupervised): {unsup_flags.sum()} / {len(df)}\\n\")\n",
        "\n",
        "df[\"unsup_score\"] = unsup_scores\n",
        "df[\"unsup_flag\"] = unsup_flags\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4️⃣ SUPERVISED MODEL (if labels available)\n",
        "# ------------------------------------------\n",
        "if is_labeled:\n",
        "    print(\"🧠 Running Supervised Model (HistGradientBoosting + SMOTE)...\")\n",
        "\n",
        "    X = df.drop(columns=[\"label\"], errors=\"ignore\").copy()\n",
        "    y = df[\"label\"].apply(lambda x: 0 if x == \"benign\" else 1)\n",
        "\n",
        "    # Encode categorical columns\n",
        "    for col in X.select_dtypes(include='object').columns:\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "    # Split & balance data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    supervised_model = HistGradientBoostingClassifier(\n",
        "        max_iter=100, learning_rate=0.1, max_depth=5, random_state=42\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    supervised_model.fit(X_train_bal, y_train_bal)\n",
        "    supervised_time = time.time() - start_time\n",
        "\n",
        "    y_prob = supervised_model.predict_proba(X_test)[:, 1]\n",
        "    y_pred = supervised_model.predict(X_test)\n",
        "    supervised_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"✅ Supervised Model Accuracy: {supervised_acc:.4f}\")\n",
        "    print(f\"⏱️ Training Time: {supervised_time:.2f} sec\\n\")\n",
        "\n",
        "    # Scale supervised scores\n",
        "    supervised_scaled = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())\n",
        "\n",
        "else:\n",
        "    supervised_scaled = np.zeros(len(df))  # No supervised data\n",
        "    supervised_acc = 0\n",
        "    supervised_time = 0\n",
        "\n",
        "# ------------------------------------------\n",
        "# 5️⃣ HYBRID ENSEMBLE COMBINATION\n",
        "# ------------------------------------------\n",
        "print(\"⚙️ Combining Models into Hybrid Ensemble (65% Supervised + 35% Unsupervised)...\")\n",
        "\n",
        "# Normalize unsupervised scores\n",
        "unsup_scaled = (unsup_scores - unsup_scores.min()) / (unsup_scores.max() - unsup_scores.min())\n",
        "\n",
        "# Match lengths for hybrid calculation\n",
        "min_len = min(len(supervised_scaled), len(unsup_scaled))\n",
        "hybrid_score = 0.65 * supervised_scaled[:min_len] + 0.35 * unsup_scaled[:min_len]\n",
        "hybrid_pred = (hybrid_score > 0.5).astype(int)\n",
        "\n",
        "df[\"hybrid_score\"] = np.pad(hybrid_score, (0, len(df) - len(hybrid_score)), 'constant')\n",
        "df[\"hybrid_flag\"] = np.pad(hybrid_pred, (0, len(df) - len(hybrid_pred)), 'constant')\n",
        "\n",
        "print(\"✅ Hybrid Model Combination Complete!\\n\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 6️⃣ EVALUATION (if labeled data available)\n",
        "# ------------------------------------------\n",
        "if is_labeled:\n",
        "    print(\"📊 Hybrid Model Evaluation on Known Data:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test[:min_len], hybrid_pred))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test[:min_len], hybrid_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test[:min_len], hybrid_pred))\n",
        "else:\n",
        "    print(\"ℹ️ Unlabeled dataset – accuracy not available (unsupervised mode).\\n\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 7️⃣ DISPLAY TOP SUSPICIOUS TRANSACTIONS\n",
        "# ------------------------------------------\n",
        "top_suspicious = df.sort_values(by=\"hybrid_score\", ascending=False).head(10)\n",
        "print(\"🔎 Top 10 Suspicious Transactions:\\n\")\n",
        "print(top_suspicious.head(10))\n",
        "\n",
        "# ------------------------------------------\n",
        "# 8️⃣ SAVE RESULTS\n",
        "# ------------------------------------------\n",
        "output_path = \"ransomware_detection_results.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"\\n💾 Results saved to: {output_path}\")\n",
        "print(f\"✅ Hybrid Ransomware Detection Completed Successfully!\\n\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 9️⃣ SUMMARY\n",
        "# ------------------------------------------\n",
        "print(\"📘 SUMMARY REPORT\")\n",
        "print(f\"🧠 Supervised Accuracy: {supervised_acc:.4f}\")\n",
        "print(f\"🚨 Total Suspicious (Hybrid): {df['hybrid_flag'].sum()} / {len(df)}\")\n",
        "print(f\"⏱️ Total Processing Time: {unsup_time + supervised_time:.2f} sec\")\n",
        "print(\"\\nProgram finished successfully ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpmGlINKezWG",
        "outputId": "1840858c-d9aa-4c88-eaca-790f10a55d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 Enter path to your dataset (CSV or ZIP file): CSV\n"
          ]
        }
      ]
    }
  ]
}